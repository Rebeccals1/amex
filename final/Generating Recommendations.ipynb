{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "HmKUBX906VMy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import ast\n",
    "from util import check_user_exists, lookup_product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Z7TVtklb7Fzo"
   },
   "outputs": [],
   "source": [
    "users_final = pd.read_csv('https://raw.githubusercontent.com/ardahk/amex/refs/heads/main/final/users_final_data.csv')\n",
    "products_final= pd.read_csv('https://raw.githubusercontent.com/ardahk/amex/refs/heads/main/final/products_final_data.csv')\n",
    "original_products = pd.read_csv('https://raw.githubusercontent.com/ardahk/amex/refs/heads/main/data/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bi51sP00F99X"
   },
   "source": [
    "## Building baseline 2 tower model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fABVEyuHHrcS"
   },
   "source": [
    "### The first issue is that for each training batch, we need to have the same amount of user-item pairs as input. This means we need to use some sort of sampling for each batch in order to make sure they're both the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Ci_eiOHmGp5-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dot, BatchNormalization\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "VtJdhlpvGtLl"
   },
   "outputs": [],
   "source": [
    "user_input = Input(shape=(16,), name='user_input')\n",
    "item_input = Input(shape=(30,), name='item_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "qq3EkB2QKFcW"
   },
   "outputs": [],
   "source": [
    "#Changed from baseline\n",
    "user_tower = Dense(128, activation='relu')(user_input)\n",
    "user_tower = BatchNormalization()(user_tower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "JAkg1EEFKHkI"
   },
   "outputs": [],
   "source": [
    "item_tower = Dense(128, activation='relu')(item_input)\n",
    "item_tower = BatchNormalization()(item_tower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "5eUzjcX2KLL1"
   },
   "outputs": [],
   "source": [
    "dot_product = Dot(axes=1)([user_tower, item_tower])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "GavRe9ZyKTih"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[user_input, item_input], outputs=dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "dSzg_ncqKU-S"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "Tx5fID2aKmB8",
    "outputId": "b2a0b00c-e299-41ed-f19b-8cf259598826"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m2,176\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m3,968\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_1 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,168</span> (28.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,168\u001b[0m (28.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,656</span> (26.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,656\u001b[0m (26.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPgKJCIxQnmp",
    "outputId": "dc1c6bb4-31fc-4802-ff94-b3b6c90cdcee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['user_input', 'item_input']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['user_input', 'item_input']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Accuracy: 0.4600, Precision: 0.4600, Recall: 1.0000, F1 Score: 0.6301, ROC AUC: 0.4565\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 2/20 - Accuracy: 0.4600, Precision: 0.4600, Recall: 1.0000, F1 Score: 0.6301, ROC AUC: 0.5894\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 3/20 - Accuracy: 0.4600, Precision: 0.4600, Recall: 1.0000, F1 Score: 0.6301, ROC AUC: 0.5338\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 4/20 - Accuracy: 0.4700, Precision: 0.4646, Recall: 1.0000, F1 Score: 0.6345, ROC AUC: 0.5427\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 5/20 - Accuracy: 0.4700, Precision: 0.4646, Recall: 1.0000, F1 Score: 0.6345, ROC AUC: 0.5616\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 6/20 - Accuracy: 0.4700, Precision: 0.4646, Recall: 1.0000, F1 Score: 0.6345, ROC AUC: 0.4416\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 7/20 - Accuracy: 0.4600, Precision: 0.4600, Recall: 1.0000, F1 Score: 0.6301, ROC AUC: 0.4887\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 8/20 - Accuracy: 0.4600, Precision: 0.4600, Recall: 1.0000, F1 Score: 0.6301, ROC AUC: 0.5169\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 9/20 - Accuracy: 0.4800, Precision: 0.4694, Recall: 1.0000, F1 Score: 0.6389, ROC AUC: 0.5552\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 10/20 - Accuracy: 0.4500, Precision: 0.4536, Recall: 0.9565, F1 Score: 0.6154, ROC AUC: 0.4638\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 11/20 - Accuracy: 0.4600, Precision: 0.4592, Recall: 0.9783, F1 Score: 0.6250, ROC AUC: 0.4147\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 12/20 - Accuracy: 0.4400, Precision: 0.4468, Recall: 0.9130, F1 Score: 0.6000, ROC AUC: 0.5012\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 13/20 - Accuracy: 0.4700, Precision: 0.4632, Recall: 0.9565, F1 Score: 0.6241, ROC AUC: 0.5089\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 14/20 - Accuracy: 0.4500, Precision: 0.4545, Recall: 0.9783, F1 Score: 0.6207, ROC AUC: 0.4533\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 15/20 - Accuracy: 0.4800, Precision: 0.4681, Recall: 0.9565, F1 Score: 0.6286, ROC AUC: 0.4767\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 16/20 - Accuracy: 0.4600, Precision: 0.4583, Recall: 0.9565, F1 Score: 0.6197, ROC AUC: 0.5266\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 17/20 - Accuracy: 0.4700, Precision: 0.4632, Recall: 0.9565, F1 Score: 0.6241, ROC AUC: 0.5254\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 18/20 - Accuracy: 0.4700, Precision: 0.4639, Recall: 0.9783, F1 Score: 0.6294, ROC AUC: 0.5713\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 19/20 - Accuracy: 0.4500, Precision: 0.4505, Recall: 0.8913, F1 Score: 0.5985, ROC AUC: 0.4287\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 20/20 - Accuracy: 0.4500, Precision: 0.4516, Recall: 0.9130, F1 Score: 0.6043, ROC AUC: 0.5028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def create_labels_and_train(users_df, products_df, model, batch_size, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        # initilize the target similarity for the batch\n",
    "        target_similarity = []\n",
    "\n",
    "        # we're making the target similarity balanced, so there's an equal number of posivie and negetive indices in each batch\n",
    "        num_indices = batch_size // 2\n",
    "\n",
    "        # generating 1/2 batch size of random pairs, where there are positive indices (user and product have the same ID)\n",
    "        positive_user_indices = np.random.randint(0, len(users_df), size=num_indices)\n",
    "        # initialize storage of positive indicies\n",
    "        positive_product_indices = []\n",
    "        # loop over every user\n",
    "        for user_idx in positive_user_indices:\n",
    "            # locating product IDs in the user dataframe for the user we sampled\n",
    "            user_product_id = users_df.iloc[user_idx]['product_id']\n",
    "            # finding matching products in the products dataframe\n",
    "            matching_products = products_df[products_df['product_id'] == user_product_id]\n",
    "            # append the matching product to the positive product indices\n",
    "            positive_product_indices.append(matching_products.index[0])\n",
    "\n",
    "        # Generate random negative pairs (user and product have different product_ids)\n",
    "        negative_user_indices = np.random.randint(0, len(users_df), size=num_indices)\n",
    "        #print(\"NEGATIVE USER INDICES: \", negative_user_indices)\n",
    "        negative_product_indices = []\n",
    "        for user_idx in negative_user_indices:\n",
    "            user_product_id = users_df.iloc[user_idx]['product_id']\n",
    "            # find a product that doesn't have a matching product id\n",
    "            non_matching_products = products_df[products_df['product_id'] != user_product_id]\n",
    "            # append that to the negetive indicies\n",
    "            negative_product_indices.append(non_matching_products.sample(1).index[0])\n",
    "\n",
    "        # combining both positive and negetive indicies\n",
    "        user_indices = np.concatenate([positive_user_indices, negative_user_indices])\n",
    "        product_indices = np.concatenate([positive_product_indices, negative_product_indices])\n",
    "\n",
    "        # create target similarity labels for the positive and negetive pairs\n",
    "        target_similarity.extend([1] * num_indices)  # Positive pairs\n",
    "        target_similarity.extend([0] * num_indices)  # Negative pairs\n",
    "        target_similarity = np.array(target_similarity)\n",
    "\n",
    "        # get the positive & negetive user data\n",
    "        user_data = users_df.iloc[user_indices]\n",
    "        user_ids = user_data['user_id'].tolist()\n",
    "        product_data = products_df.iloc[product_indices]\n",
    "        item_ids = product_data['product_id'].tolist()\n",
    "\n",
    "        user_data = user_data.drop(columns=['product_id', 'user_id'])\n",
    "        product_data = product_data.drop(columns=['product_id', 'flattened_name_embedding', 'flattened_brand_embedding'])\n",
    "\n",
    "        # Split data into training and testing sets\n",
    "        X_train_users, X_test_users, X_train_products, X_test_products, y_train, y_test = train_test_split(\n",
    "            user_data, product_data, target_similarity, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Train the model on the training data\n",
    "        model.fit([X_train_users, X_train_products], y_train, epochs=1, batch_size=batch_size, verbose=False)\n",
    "\n",
    "        # Predict on the test data\n",
    "        predicted_probabilities = model.predict([X_test_users, X_test_products]).flatten()\n",
    "\n",
    "        # Convert probabilities to binary predictions\n",
    "        y_pred = (predicted_probabilities > 0.5).astype(int)\n",
    "\n",
    "        # Evaluate the model on the test data\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, predicted_probabilities)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - \"\n",
    "              f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, \"\n",
    "              f\"F1 Score: {f1:.4f}, ROC AUC: {auc:.4f}\")\n",
    "\n",
    "# Parameters\n",
    "batch_size = 500\n",
    "num_epochs = 20\n",
    "\n",
    "create_labels_and_train(users_final, products_final, model, batch_size, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code splits the data into training and testing data, and trains the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13800 entries, 0 to 13799\n",
      "Data columns (total 33 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   cost                                    13800 non-null  float64\n",
      " 1   retail_price                            13800 non-null  float64\n",
      " 2   product_id                              13800 non-null  int64  \n",
      " 3   flattened_name_embedding                13800 non-null  object \n",
      " 4   flattened_brand_embedding               13800 non-null  object \n",
      " 5   department_Men                          13800 non-null  int64  \n",
      " 6   department_Women                        13800 non-null  int64  \n",
      " 7   category_Accessories                    13800 non-null  int64  \n",
      " 8   category_Active                         13800 non-null  int64  \n",
      " 9   category_Blazers & Jackets              13800 non-null  int64  \n",
      " 10  category_Clothing Sets                  13800 non-null  int64  \n",
      " 11  category_Dresses                        13800 non-null  int64  \n",
      " 12  category_Fashion Hoodies & Sweatshirts  13800 non-null  int64  \n",
      " 13  category_Intimates                      13800 non-null  int64  \n",
      " 14  category_Jeans                          13800 non-null  int64  \n",
      " 15  category_Jumpsuits & Rompers            13800 non-null  int64  \n",
      " 16  category_Leggings                       13800 non-null  int64  \n",
      " 17  category_Maternity                      13800 non-null  int64  \n",
      " 18  category_Outerwear & Coats              13800 non-null  int64  \n",
      " 19  category_Pants                          13800 non-null  int64  \n",
      " 20  category_Pants & Capris                 13800 non-null  int64  \n",
      " 21  category_Plus                           13800 non-null  int64  \n",
      " 22  category_Shorts                         13800 non-null  int64  \n",
      " 23  category_Skirts                         13800 non-null  int64  \n",
      " 24  category_Sleep & Lounge                 13800 non-null  int64  \n",
      " 25  category_Socks                          13800 non-null  int64  \n",
      " 26  category_Socks & Hosiery                13800 non-null  int64  \n",
      " 27  category_Suits                          13800 non-null  int64  \n",
      " 28  category_Suits & Sport Coats            13800 non-null  int64  \n",
      " 29  category_Sweaters                       13800 non-null  int64  \n",
      " 30  category_Swim                           13800 non-null  int64  \n",
      " 31  category_Tops & Tees                    13800 non-null  int64  \n",
      " 32  category_Underwear                      13800 non-null  int64  \n",
      "dtypes: float64(2), int64(29), object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "products_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(test_users_df, products_df, model, top_n=10):\n",
    "    # Randomly select a user\n",
    "    random_user_row = test_users_df.sample(1)\n",
    "    random_user_id = random_user_row['user_id'].values[0]\n",
    "    print(f\"Generating recommendations for user ID: {random_user_id}...\")\n",
    "\n",
    "    # Prepare user data for the selected user\n",
    "    user_data = random_user_row.drop(columns=['product_id', 'user_id']).values\n",
    "    user_data_repeated = np.repeat(user_data, len(products_df), axis=0)\n",
    "\n",
    "    # Prepare product data\n",
    "    product_data = products_df.drop(columns=['product_id', 'flattened_name_embedding', 'flattened_brand_embedding']).values\n",
    "\n",
    "    print(\"User data repeated shape:\", user_data_repeated.shape)\n",
    "    print(\"Product data shape:\", product_data.shape)\n",
    "    # Predict probabilities\n",
    "    predicted_probabilities = model.predict([user_data_repeated, product_data]).flatten()\n",
    "\n",
    "    # Sort product recommendations by increasing probability\n",
    "    sorted_indices = np.argsort(predicted_probabilities)\n",
    "    sorted_products = products_df.iloc[sorted_indices]\n",
    "\n",
    "    # Display top N recommendations\n",
    "    top_recommendations = sorted_products.head(top_n)\n",
    "    #print(\"Top recommendations (sorted by increasing probability of interaction):\")\n",
    "    #print(top_recommendations[['product_id']])\n",
    "\n",
    "    #Returns a list of the top n product IDs\n",
    "    return top_recommendations[['product_id']]['product_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29120 entries, 0 to 29119\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      29120 non-null  int64  \n",
      " 1   cost                    29120 non-null  float64\n",
      " 2   category                29120 non-null  object \n",
      " 3   name                    29118 non-null  object \n",
      " 4   brand                   29096 non-null  object \n",
      " 5   retail_price            29120 non-null  float64\n",
      " 6   department              29120 non-null  object \n",
      " 7   sku                     29120 non-null  object \n",
      " 8   distribution_center_id  29120 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "original_products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating recommendations for user ID: 94559...\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step\n",
      "ID = 28700, Name = 23027    Wayfarer Style Sunglasses Dark Lens Black Frame\n",
      "Name: name, dtype: object\n",
      "ID = 14235, Name = 1401    Indestructable Aluminum Aluma Wallet - RED\n",
      "Name: name, dtype: object\n",
      "ID = 14202, Name = 11644    GENUINE LEATHER SNAP ON STUDDED WHITE PIANO BE...\n",
      "Name: name, dtype: object\n",
      "ID = 13629, Name = 28484    Solid Color Leather Adjustable Skinny Belt with\n",
      "Name: name, dtype: object\n",
      "ID = 12536, Name = 13235    Individual Bra Extenders\n",
      "Name: name, dtype: object\n",
      "ID = 14298, Name = 16355    Classic Tear Drop Mirror Lens Aviator Sunglasses\n",
      "Name: name, dtype: object\n",
      "ID = 28913, Name = 27838    TopTie Mens Black & White Checkerboard Pre-Tie...\n",
      "Name: name, dtype: object\n",
      "ID = 25276, Name = 18410    Wool Arctic Socks\n",
      "Name: name, dtype: object\n",
      "ID = 28774, Name = 27836    TopTie Unisex Fashion Leopard Spotted Slim Tan...\n",
      "Name: name, dtype: object\n",
      "ID = 28921, Name = 7317    Designer Bow Ties for Men & Boys by Tok Tok De...\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recs = generate_recommendations(users_final, products_final, model, top_n=10)\n",
    "recs\n",
    "lookup_product_name(recs, original_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Recommendations for a specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations_for_user(test_users_df, products_df, model, user_id, top_n=10):\n",
    "    # Get the data for the specific user\n",
    "    user_row = test_users_df[test_users_df['user_id'] == user_id]\n",
    "    \n",
    "    if user_row.empty:\n",
    "        raise ValueError(f\"User with ID {user_id} not found in the test_users_df.\")\n",
    "    \n",
    "    print(f\"Generating recommendations for user ID: {user_id}...\")\n",
    "\n",
    "    # Prepare user data for the selected user\n",
    "    user_data = user_row.drop(columns=['product_id', 'user_id']).values\n",
    "\n",
    "    # Prepare product data (drop 'product_id' and any embeddings)\n",
    "    product_data = products_df.drop(columns=['product_id', 'flattened_name_embedding', 'flattened_brand_embedding']).values\n",
    "\n",
    "    # Repeat user data for each product (model requires this structure)\n",
    "    user_data_repeated = np.repeat(user_data, product_data.shape[0], axis=0)\n",
    "\n",
    "    print(\"User data repeated shape:\", user_data_repeated.shape)\n",
    "    print(\"Product data shape:\", product_data.shape)\n",
    "    # Predict probabilities (model expects a list of two inputs: user data and product data)\n",
    "    predicted_probabilities = model.predict([user_data_repeated, product_data]).flatten()\n",
    "\n",
    "    # Sort product recommendations by predicted probabilities\n",
    "    sorted_indices = np.argsort(predicted_probabilities)\n",
    "    sorted_products = products_df.iloc[sorted_indices]\n",
    "\n",
    "    # Get the top N recommendations\n",
    "    top_recommendations = sorted_products.head(top_n)\n",
    "\n",
    "    # Return a list of the top N product IDs\n",
    "    return top_recommendations[['product_id']]['product_id'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID 84533 exists in the DataFrame.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_user_exists(users_final, 84533)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating recommendations for user ID: 84533...\n",
      "User data repeated shape: (55200, 16)\n",
      "Product data shape: (13800, 30)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 55200, 13800\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m recs \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_recommendations_for_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43musers_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproducts_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m84533\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m lookup_product_name(recs, original_products)\n",
      "Cell \u001b[0;32mIn[75], line 22\u001b[0m, in \u001b[0;36mgenerate_recommendations_for_user\u001b[0;34m(test_users_df, products_df, model, user_id, top_n)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct data shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, product_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Predict probabilities (model expects a list of two inputs: user data and product data)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m predicted_probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_data_repeated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Sort product recommendations by predicted probabilities\u001b[39;00m\n\u001b[1;32m     25\u001b[0m sorted_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(predicted_probabilities)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 55200, 13800\n"
     ]
    }
   ],
   "source": [
    "recs = generate_recommendations_for_user(users_final, products_final, model, 84533, top_n=10)\n",
    "lookup_product_name(recs, original_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
